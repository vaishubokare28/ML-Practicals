ML Practical 1. Data preparation
________________________________________
AIM:
To perform data preparation and performance evaluation using the Heart Disease dataset.
________________________________________
DATASET LINK:
https://www.kaggle.com/zhaoyingzhu/heartcsv
________________________________________
CODE & EXPLANATION
________________________________________
1Ô∏è‚É£ Import Required Libraries and Load Dataset
import pandas as pd
import numpy as np

# Load dataset
df = pd.read_csv("Heart.csv")

# Display first few rows
print("First 5 Rows of Dataset:\n")
print(df.head())
Explanation:
‚Ä¢	pandas and numpy are imported for data handling.
‚Ä¢	The dataset is read using pd.read_csv().
‚Ä¢	.head() displays the top 5 records to understand the structure of the data.
________________________________________
2Ô∏è‚É£ Find Shape of the Data
# Find shape of dataset
print("Shape of Data (Rows, Columns):", df.shape)
Explanation:
‚Ä¢	.shape gives the total number of rows and columns in the dataset.
‚Ä¢	Example: (303, 15) means 303 records and 15 attributes.
________________________________________
3Ô∏è‚É£ Check Missing Values
# Check missing (NaN) values in each column
print("\nMissing Values in Each Column:\n")
print(df.isnull().sum())
Explanation:
‚Ä¢	.isnull() identifies missing entries.
‚Ä¢	.sum() counts them for each column.
‚Ä¢	Helps identify incomplete data (e.g., Ca has 4 missing values).
________________________________________
4Ô∏è‚É£ Find Data Types of Each Column
# Check datatype of each column
print("\nData Types of Columns:\n")
print(df.dtypes)
Explanation:
‚Ä¢	.dtypes shows whether each column is numeric (int64, float64) or categorical (object).
‚Ä¢	Helps decide preprocessing steps for model building.
________________________________________
5Ô∏è‚É£ Find Zero Values in Dataset
# Count how many zero values exist in each column
zero_counts = (df == 0).sum()

print("\nCount of Zero Values in Each Column:\n")
print(zero_counts)
Explanation:
‚Ä¢	(df == 0) returns True for every cell equal to zero.
‚Ä¢	.sum() then counts the number of zeros per column.
‚Ä¢	Useful to detect invalid or missing-like zero values (e.g., Fbs, Ca).
________________________________________
6Ô∏è‚É£ Find Mean Age of Patients
# Calculate mean (average) age
mean_age = df["Age"].mean()
print(f"\nMean Age of Patients: {mean_age:.2f} years")
Explanation:
‚Ä¢	.mean() computes average age from the ‚ÄúAge‚Äù column.
‚Ä¢	Average age ‚âà 54.44 years ‚Üí most patients are middle-aged.
________________________________________
7Ô∏è‚É£ Extract Specific Columns and Split Dataset
# Select specific columns
selected_cols = ["Age", "Sex", "ChestPain", "RestBP", "Chol"]
subset = df[selected_cols]

print("\nSelected Columns:\n", subset.head())

# Split data into 75% training and 25% testing
from sklearn.model_selection import train_test_split

train, test = train_test_split(subset, test_size=0.25, random_state=0)

print("\nTraining Set Shape :", train.shape)
print("Testing Set Shape  :", test.shape)
Explanation:
‚Ä¢	Only required columns are extracted.
‚Ä¢	train_test_split() divides dataset into training and testing subsets.
‚Ä¢	random_state=0 ensures reproducible results.
________________________________________
8Ô∏è‚É£ Confusion Matrix and Performance Metrics
# Import libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Given problem data
TP = 45   # True Positives
FP = 55   # False Positives
FN = 5    # False Negatives
TN = 395  # True Negatives
total = 500

# Create confusion matrix
cm = [[TP, FP],
      [FN, TN]]

# Calculate metrics
accuracy = (TP + TN) / total
precision = TP / (TP + FP)
recall = TP / (TP + FN)
f1 = 2 * (precision * recall) / (precision + recall)

# Display results
print("\nConfusion Matrix Values:")
print(f"TP = {TP}, FP = {FP}, FN = {FN}, TN = {TN}")
print(f"\nAccuracy : {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall   : {recall:.2f}")
print(f"F1 Score : {f1:.2f}")
Explanation:
‚Ä¢	We manually define values for TP, FP, FN, TN as per problem.
‚Ä¢	Accuracy, Precision, Recall, and F1 Score are computed using standard formulas.
‚Ä¢	Results:
o	Accuracy = 0.88
o	Precision = 0.45
o	Recall = 0.90
o	F1 Score = 0.60
________________________________________
9Ô∏è‚É£ Visualize Confusion Matrix
# Visualize confusion matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=['Predicted Positive', 'Predicted Negative'],
            yticklabels=['Actual Positive', 'Actual Negative'])
plt.title("Confusion Matrix for COVID Prediction")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()
Explanation:
‚Ä¢	seaborn.heatmap() is used to visually represent the confusion matrix.
‚Ä¢	Each cell shows the number of predictions (TP, FP, FN, TN).
‚Ä¢	Darker cells indicate higher values (e.g., many true negatives).
________________________________________
üîü Summary of Results
Metric Summary Table
Metric	Formula	Value
Accuracy	(TP + TN) / Total	0.88
Precision	TP / (TP + FP)	0.45
Recall	TP / (TP + FN)	0.90
F1 Score	2 √ó (P √ó R) / (P + R)	0.60
Explanation:
‚Ä¢	Model has high recall ‚Üí detects most positives.
‚Ä¢	Moderate precision ‚Üí some false alarms present.
‚Ä¢	Overall accuracy is 88%, which is good for health screening models.
________________________________________
‚úÖ Conclusion
‚Ä¢	Dataset explored successfully (shape, missing values, zeros, mean age).
‚Ä¢	Extracted relevant columns and split into training/testing sets.
‚Ä¢	Evaluated performance using confusion matrix and metrics.
‚Ä¢	The model achieves 88% accuracy with strong recall (90%), showing good detection capability.
________________________________________
üßæ Viva Question‚ÄìAnswer Sheet
________________________________________
1Ô∏è‚É£ What is the aim of this practical?
Ans:
To perform data preparation and evaluate performance metrics (Accuracy, Precision, Recall, F1-score) using the Heart Disease dataset.
________________________________________
2Ô∏è‚É£ What library is used to handle datasets in Python?
Ans:
pandas is used for loading and handling datasets in Python.
________________________________________
3Ô∏è‚É£ What does df.shape return?
Ans:
It returns the number of rows and columns in the dataset.
Example: (303, 15) ‚Üí 303 rows, 15 columns.
________________________________________
4Ô∏è‚É£ How do we check for missing values?
Ans:
Using df.isnull().sum(), which counts the number of missing (NaN) values in each column.
________________________________________
5Ô∏è‚É£ What is the purpose of checking data types?
Ans:
To know which columns are numerical or categorical so that we can apply proper preprocessing or encoding techniques.
________________________________________
6Ô∏è‚É£ Why do we check for zero values?
Ans:
Because sometimes 0 can represent missing or invalid data (e.g., in medical or sensor datasets).
________________________________________
7Ô∏è‚É£ How do we find the mean age of patients?
Ans:
By using df["Age"].mean() ‚Äî it gives the average age of all patients.
________________________________________
8Ô∏è‚É£ What is the use of train_test_split()?
Ans:
It divides the dataset into training and testing sets for model building and evaluation.
Usually: 75% training and 25% testing.
________________________________________
9Ô∏è‚É£ What is a Confusion Matrix?
Ans:
It is a 2√ó2 table showing how many predictions were correct or incorrect:
	Predicted +	Predicted -
Actual +	True Positive	False Negative
Actual -	False Positive	True Negative
________________________________________
üîü Define Accuracy, Precision, Recall, and F1 Score.
Ans:
‚Ä¢	Accuracy: (TP + TN) / Total ‚Üí overall correctness
‚Ä¢	Precision: TP / (TP + FP) ‚Üí correctness of positive predictions
‚Ä¢	Recall: TP / (TP + FN) ‚Üí how many actual positives were found
‚Ä¢	F1 Score: 2 √ó (Precision √ó Recall) / (Precision + Recall) ‚Üí balance between precision & recall
________________________________________
1Ô∏è‚É£1Ô∏è‚É£ What were the metric values in this experiment?
Ans:
‚Ä¢	Accuracy = 0.88
‚Ä¢	Precision = 0.45
‚Ä¢	Recall = 0.90
‚Ä¢	F1 Score = 0.60
________________________________________
1Ô∏è‚É£2Ô∏è‚É£ What does high recall indicate in this context?
Ans:
It means the model is good at identifying most of the actual positive (heart disease) cases ‚Äî fewer false negatives.
________________________________________
1Ô∏è‚É£3Ô∏è‚É£ Why is recall important in medical datasets?
Ans:
Because missing a positive case (disease) is more serious than a false alarm. Hence, high recall is crucial.
________________________________________
1Ô∏è‚É£4Ô∏è‚É£ What is the average age of patients in the dataset?
Ans:
Around 54 years, meaning most patients are middle-aged adults.
________________________________________
1Ô∏è‚É£5Ô∏è‚É£ What is the final conclusion of this practical?
Ans:
The Heart dataset was successfully analyzed and cleaned.
Performance evaluation showed 88% accuracy and high recall, which is ideal for medical prediction tasks.
________________________________________

